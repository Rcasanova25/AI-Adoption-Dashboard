[tool:pytest]
# Pytest configuration for AI Adoption Dashboard

# Test discovery
testpaths = tests
python_files = test_*.py *_test.py
python_classes = Test*
python_functions = test_*

# Markers
markers =
    slow: marks tests as slow (deselect with -m "not slow")
    integration: marks tests as integration tests  
    performance: marks tests as performance tests
    accessibility: marks tests as accessibility tests
    unit: marks tests as unit tests
    automated: marks tests as automated tests

# Output options
addopts = 
    --strict-markers
    --strict-config
    --verbose
    --tb=short
    --durations=10
    --color=yes

# Coverage options (when coverage is enabled)
# --cov=data
# --cov=views
# --cov=business
# --cov=Utils
# --cov-report=term-missing
# --cov-report=html:htmlcov
# --cov-fail-under=70

# Filtering
filterwarnings =
    ignore::UserWarning
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning

# Logging
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Timeouts
timeout = 300