# file: C:\Users\rcasa\OneDrive\Documents\AI-Adoption-Dashboard\business\risk_assessment.py
# hypothesis_version: 6.135.20

[0.0, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 3.0, 5.0, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0, 30000, 50000, 80000, 100000, 120000, 150000, 200000, 250000, 300000, 500000, 1000000, '1-50', '5000+', 'A/B testing', 'AI Skills Gap', 'Adoption rates', 'Assessed', 'Bias metrics', 'Budget Overruns', 'Budget variance', 'Competitive analysis', 'Continuous training', 'Cost per outcome', 'Cost tracking', 'Critical', 'Data accuracy', 'Data completeness', 'Data drift detection', 'Data governance', 'Data usage audits', 'Data validation', 'Ethical', 'External hiring', 'Fairness assessments', 'Financial', 'Financial Services', 'Government', 'Healthcare', 'High', 'Identified', 'Innovation metrics', 'Legal review', 'Low', 'Manufacturing', 'Market share', 'Medium', 'Mitigated', 'Model accuracy', 'Monitored', 'Operational', 'Outcome equity', 'Poor Data Quality', 'Prediction latency', 'Privacy compliance', 'Quality monitoring', 'ROI tracking', 'Regular audits', 'Regulatory', 'Regulatory updates', 'Response times', 'RiskAssessment', 'RiskAssessmentEngine', 'RiskCategory', 'RiskFactor', 'RiskLevel', 'RiskStatus', 'Strategic', 'System utilization', 'Technical', 'Technology', 'Throughput', 'Training programs', 'User consent rates', 'Value realization', 'competitive_risk', 'data_quality', 'data_sensitivity', 'escalation', 'ethical_risks', 'financial_risks', 'frequency', 'innovation_pressure', 'metrics', 'model_performance', 'operational_risk', 'operational_risks', 'regulatory_risk', 'regulatory_risks', 'reporting', 'review', 'safety_concerns', 'skills_gap', 'strategic_risks', 'technical_risks']